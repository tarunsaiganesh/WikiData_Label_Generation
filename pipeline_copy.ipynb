{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f46beab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding strong links for:  History of Rome\n",
      "Found  8  strong links\n",
      "Total network size:  12740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (427 of 12740) |                    | Elapsed Time: 0:03:18 ETA:   3:07:21"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Lucius_Marcius_Philippus_(consul_91_BC)\" title=\"Lucius Marcius Philippus (consul 91 BC)\">L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      "  3% (427 of 12740) |                    | Elapsed Time: 0:03:18 ETA:   3:32:29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Marcus_Aemilius_Lepidus_(triumvir)\" title=\"Marcus Aemilius Lepidus (triumvir)\">M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6% (884 of 12740) |#                   | Elapsed Time: 0:06:49 ETA:   1:18:52"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/J._R._R._Tolkien\" title=\"J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9% (1151 of 12740) |#                  | Elapsed Time: 0:08:50 ETA:   1:51:05"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Robert_E._Howard\" title=\"Robert E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9% (1211 of 12740) |#                  | Elapsed Time: 0:09:15 ETA:   1:18:54"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/National_Fascist_Party\" title=\"National Fascist Party\">National Fascist Party\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      "  9% (1211 of 12740) |#                  | Elapsed Time: 0:09:15 ETA:   1:36:26"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/National_Fascist_Party\" title=\"National Fascist Party\">National Fascist Party\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12% (1624 of 12740) |##                 | Elapsed Time: 0:12:36 ETA:   1:19:59"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse page:  List of sovereign states in 1528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14% (1857 of 12740) |##                 | Elapsed Time: 0:14:25 ETA:   1:11:37"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/J._R._R._Tolkien\" title=\"J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16% (2114 of 12740) |###                | Elapsed Time: 0:16:22 ETA:   1:06:36"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/J._R._R._Tolkien\" title=\"J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17% (2257 of 12740) |###                | Elapsed Time: 0:17:22 ETA:   1:06:51"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Publius_Canidius_Crassus\" title=\"Publius Canidius Crassus\">P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25% (3274 of 12740) |####               | Elapsed Time: 0:24:40 ETA:   0:59:36"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Bernard_of_Clairvaux\" title=\"Bernard of Clairvaux\">St\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26% (3345 of 12740) |####               | Elapsed Time: 0:25:09 ETA:   0:50:27"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/M._C._Escher\" title=\"M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% (5207 of 12740) |#######            | Elapsed Time: 0:38:04 ETA:   0:43:39"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/J._R._R._Tolkien\" title=\"J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48% (6178 of 12740) |#########          | Elapsed Time: 0:44:42 ETA:   0:46:37"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/J._R._R._Tolkien\" title=\"J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53% (6841 of 12740) |##########         | Elapsed Time: 0:49:20 ETA:   0:36:35"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse page:  List of sovereign states in 1662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54% (6890 of 12740) |##########         | Elapsed Time: 0:49:41 ETA:   0:34:40"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse page:  List of sovereign states in 1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54% (6963 of 12740) |##########         | Elapsed Time: 0:50:13 ETA:   0:41:56"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/J._R._R._Tolkien\" title=\"J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56% (7150 of 12740) |##########         | Elapsed Time: 0:51:31 ETA:   0:37:26"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Lucius_Tarquinius_Superbus\" title=\"Lucius Tarquinius Superbus\">L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      " 56% (7150 of 12740) |##########         | Elapsed Time: 0:51:32 ETA:   0:42:20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Lucius_Junius_Brutus\" title=\"Lucius Junius Brutus\">L\n",
      "failed to parse link text:  \"/wiki/Lucius_Tarquinius_Superbus\" title=\"Lucius Tarquinius Superbus\">L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57% (7268 of 12740) |##########         | Elapsed Time: 0:52:19 ETA:   0:34:10"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Catholic_Church\" title=\"Catholic Church\">Roman \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% (7710 of 12740) |###########        | Elapsed Time: 0:55:22 ETA:   0:34:43"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse page:  List of sovereign states in 1660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62% (7928 of 12740) |###########        | Elapsed Time: 0:56:51 ETA:   0:37:05"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Cape_St._Vincent\" title=\"Cape St\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65% (8321 of 12740) |############       | Elapsed Time: 0:59:36 ETA:   0:32:52"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Augustine_of_Hippo\" title=\"Augustine of Hippo\">St\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66% (8481 of 12740) |############       | Elapsed Time: 1:00:47 ETA:   0:50:10"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse page:  List of sovereign states in 1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      " 66% (8481 of 12740) |############       | Elapsed Time: 1:00:47 ETA:   0:57:49"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/M._C._Escher\" title=\"M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67% (8556 of 12740) |############       | Elapsed Time: 1:01:15 ETA:   0:29:06"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/J._R._R._Tolkien\" title=\"J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74% (9446 of 12740) |##############     | Elapsed Time: 1:07:33 ETA:   0:20:21"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not retrieve data for page:  Cushitic peoples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79% (10137 of 12740) |##############    | Elapsed Time: 1:12:20 ETA:   0:17:14"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse page:  List of battles 1301–1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83% (10588 of 12740) |##############    | Elapsed Time: 1:15:23 ETA:   0:12:59"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Pope_Pius_IX\" title=\"Pope Pius IX\">Bl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83% (10670 of 12740) |###############   | Elapsed Time: 1:15:57 ETA:   0:12:22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/J._R._R._Tolkien\" title=\"J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85% (10883 of 12740) |###############   | Elapsed Time: 1:17:22 ETA:   0:10:23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Francis_of_Assisi\" title=\"Francis of Assisi\">St\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86% (11078 of 12740) |###############   | Elapsed Time: 1:18:39 ETA:   0:10:13"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/M._C._Escher\" title=\"M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89% (11343 of 12740) |################  | Elapsed Time: 1:20:24 ETA:   0:08:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Jerome\" title=\"Jerome\">St\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% (11511 of 12740) |################  | Elapsed Time: 1:21:34 ETA:   0:06:54"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/List_of_obelisks_in_Rome\" title=\"List of obelisks in Rome\">St\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91% (11649 of 12740) |################  | Elapsed Time: 1:22:31 ETA:   0:07:06"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Gnaeus_Octavius_(consul_87_BC)\" title=\"Gnaeus Octavius (consul 87 BC)\">Cn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      " 91% (11649 of 12740) |################  | Elapsed Time: 1:22:31 ETA:   0:07:44"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Augustus\" title=\"Augustus\">C\n",
      "failed to parse link text:  \"/wiki/Roman_emperor\" title=\"Roman emperor\">imp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96% (12339 of 12740) |################# | Elapsed Time: 1:27:25 ETA:   0:02:26"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/J._R._R._Tolkien\" title=\"J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96% (12342 of 12740) |################# | Elapsed Time: 1:27:26 ETA:   0:02:40"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse link text:  \"/wiki/Carlo_Emanuele_Muzzarelli\" title=\"Carlo Emanuele Muzzarelli\">C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (12740 of 12740) |##################| Elapsed Time: 1:30:23 Time:  1:30:23\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import string\n",
    "import re\n",
    "import urllib.parse\n",
    "import csv\n",
    "import time\n",
    "from py2neo import Graph\n",
    "from queue import Queue\n",
    "import progressbar\n",
    "import numpy as np\n",
    "import os\n",
    "import pyparsing as pp\n",
    "\n",
    "def runWithRetry(query):\n",
    "    try:\n",
    "        return graph.run(query)\n",
    "    except Exception as e:\n",
    "        print(e.args[0])\n",
    "        time.sleep(1)\n",
    "        return runWithRetry(query)\n",
    "\n",
    "def getWithRetry(url):\n",
    "    try:\n",
    "        return requests.get(url)\n",
    "    except Exception:\n",
    "        print(\"Connection timed out and retrying URL: \", url)\n",
    "        time.sleep(1)\n",
    "        return getWithRetry(url)\n",
    "    \n",
    "graph = Graph(\"http://localhost:7474/db/data/\")\n",
    "    \n",
    "def main():\n",
    "    output_filename = \"roman_history_results\"\n",
    "    primaryDomain = \"History of Rome\"\n",
    "    repo_name = \"roman_history_wd_links\"\n",
    "    \n",
    "    if os.path.exists(\"data/output/\"+output_filename+\"_all_results.txt\") == False:\n",
    "        strongLinks = getStrongLinks(primaryDomain)\n",
    "        #strongLinks = [primaryDomain]\n",
    "        strongLinks.remove(\"Rome\")\n",
    "        networkHops = 1\n",
    "        networkList, redirectMap = getWikipediaNetworkList(strongLinks, networkHops)\n",
    "        linkData = parseWikipediaPagesInNetwork(networkList, redirectMap)\n",
    "\n",
    "        with open(\"data/output/\"+output_filename+\"_all_results.txt\", 'w', newline='', encoding = \"utf-8\") as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "            writer.writerows(linkData)\n",
    "    \n",
    "    linkData = []\n",
    "    with open(\"data/output/\"+output_filename+\"_all_results.txt\", 'r', encoding = \"utf-8\") as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        for row in reader:\n",
    "            linkData.append(row)\n",
    "    \n",
    "    #training_data, test_data = checkWikidataForConnections(linkData, repo_name)\n",
    "    \n",
    "    #print(\"final training size: \", len(training_data))\n",
    "    #headers = ['Origin Page','Destination Page','Link Text','Sentence Text','Wikidata Property Label','Direction']\n",
    "    #with open(\"data/output/training/\"+output_filename+\"_training.txt\", 'w', newline='', encoding = \"utf-8\") as csvfile:\n",
    "    #    writer = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    #    writer.writerow(headers)\n",
    "    #    writer.writerows(training_data)\n",
    "\n",
    "    #print(\"final test size: \", len(test_data))\n",
    "    #headers = ['Origin Page','Destination Page','Link Text','Sentence Text']\n",
    "    #with open(\"data/output/test/\"+output_filename+\"_test.txt\", 'w', newline='', encoding = \"utf-8\") as csvfile:\n",
    "    #    writer = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    #    writer.writerow(headers)\n",
    "    #    writer.writerows(test_data)\n",
    "\n",
    "# Neo4j Cypher lookup\n",
    "# Handles page redirects cleanly\n",
    "def getWikipediaNetworkList(domains, networkHops):\n",
    "    param_query = \"MATCH (source:Page {title: \\\"subj\\\"}) {direction} (target:Page) RETURN target.title\"\n",
    "    networkList = set()\n",
    "    redirectMap = {}\n",
    "    for domain in domains:\n",
    "        queue = Queue()\n",
    "        queue.put({domain:0})\n",
    "        networkList.add(domain)\n",
    "        while(queue.empty() == False):\n",
    "            nextItem = queue.get()\n",
    "            element = next(iter(nextItem))\n",
    "            layer = nextItem[element]\n",
    "            if layer >= networkHops:\n",
    "                break\n",
    "            query = param_query.replace(\"subj\", element.replace(\"\\\"\",\"\\\\\\\"\")).replace(\"{direction}\", \"- [:Link] -\")\n",
    "            query_data = runWithRetry(query).data()\n",
    "            for res in query_data:\n",
    "                page = res[\"target.title\"]\n",
    "                # Get only forward links to see if page is a redirect\n",
    "                query = param_query.replace(\"subj\", page.replace(\"\\\"\",\"\\\\\\\"\")).replace(\"{direction}\", \"- [:Link] -> \")\n",
    "                query_data = runWithRetry(query).data()\n",
    "                if (len(query_data) == 1):\n",
    "                    redirected_page = query_data[0][\"target.title\"]\n",
    "                    #print(\"Found redirect: \", page, \" to \", redirected_page)\n",
    "                    redirectMap[page] = redirected_page\n",
    "                    page = redirected_page\n",
    "                networkList.add(page)\n",
    "                queue.put({page:layer+1})\n",
    "    print(\"Total network size: \", str(len(networkList)))\n",
    "    return networkList, redirectMap\n",
    "\n",
    "# Request and parse Wikipedia HTML\n",
    "# Only parses introduction/abstract section of pages\n",
    "# A shortcoming is that this code will fail to parse link text with a . in it\n",
    "def parseWikipediaPagesInNetwork(networkList, redirectMap):\n",
    "    linkData = []\n",
    "    for line in progressbar.progressbar(networkList, redirect_stdout=True):\n",
    "        if line in redirectMap:\n",
    "            line = redirectMap[line]\n",
    "            print(\"Redirected to: \", line)\n",
    "        pageTitle = urllib.parse.quote(line)\n",
    "        getUrl = f\"https://en.wikipedia.org/w/api.php?action=parse&page={pageTitle}&format=json\"\n",
    "        jsonRes = getWithRetry(getUrl).json()\n",
    "        if 'parse' not in jsonRes:\n",
    "            print(\"Could not retrieve data for page: \", line)\n",
    "        else:\n",
    "            jsonRes = jsonRes['parse']['text']['*']\n",
    "            absStart = jsonRes.split(\"<p>\", 1)\n",
    "            if len(absStart) == 1:\n",
    "                print(\"Unable to parse page: \", line)\n",
    "            else:\n",
    "                absText = absStart[1].split(\"<h2\")[0]\n",
    "                sentences = re.split(r'\\n|\\. |\\.<sup id=', absText)\n",
    "                for i in sentences:\n",
    "                    linkSplit = i.split(\"<a href=\")\n",
    "                    if len(linkSplit) > 1:\n",
    "                        for link in linkSplit:\n",
    "                            if link.startswith(\"\\\"/wiki/\"):\n",
    "                                destinationPage = link.split(\"\\\"/wiki/\")[1].split(\"\\\"\")[0]\n",
    "                                if destinationPage.replace(\"_\",\" \") in networkList:\n",
    "                                    if \">\" not in link or \"<\" not in link:\n",
    "                                        print(\"failed to parse link text: \", link)\n",
    "                                    else:\n",
    "                                        linkTitle = link.split(\">\")[1].split(\"<\")[0]\n",
    "                                        sentString = re.sub('<[^>]+>', '', i)\n",
    "                                        sentString = sentString.translate(str.maketrans('', '', string.punctuation))\n",
    "                                        sentString = re.sub('91[0-9]+93', '', sentString)\n",
    "                                        destinationPage = destinationPage.replace(\"|\",\"\")\n",
    "                                        linkTitle = linkTitle.replace(\"|\",\"\")\n",
    "                                        if sentString.startswith(\"citeref\"):\n",
    "                                            sentString = sentString.split(\" \",2)[2]\n",
    "                                        if \"redirect\" not in sentString:\n",
    "                                            newRow = [line.replace(\"_\",\" \"), destinationPage.replace(\"_\",\" \"), linkTitle, sentString]\n",
    "                                            linkData.append(newRow)\n",
    "    return linkData\n",
    "\n",
    "# Query Wikidata SPARQL Endpoint\n",
    "def checkWikidataForConnections(linkData, repo_name):\n",
    "    filedir = \"data/output/\"\n",
    "    queryHead = f\"http://localhost:7200/repositories/{repo_name}?name=&infer=false&sameAs=false&query=\"\n",
    "    training_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    queryTail = \"select ?s ?p ?o where {\"\n",
    "    itemsInQuery = {}\n",
    "    # \"header too big\" error when set to 50\n",
    "    batchSize = 10\n",
    "    batchCount = 0\n",
    "    \n",
    "    #for i in progressbar.progressbar(range(len(linkData)), redirect_stdout=True):\n",
    "    for i in range(len(linkData)):\n",
    "        #print(linkData[i])\n",
    "        if queryTail == \"select ?s ?p ?o where {\":\n",
    "            queryTail += \"{\"\n",
    "        else:\n",
    "            queryTail += \"UNION {\"\n",
    "        subj = \"<https://en.wikipedia.org/wiki/\" + linkData[i][0].replace(\" \",\"_\") + \">\"\n",
    "        obj = \"<https://en.wikipedia.org/wiki/\" + linkData[i][1].replace(\" \",\"_\") + \">\"\n",
    "        queryTail += \"VALUES ?s {\"+subj+\"} VALUES ?o {\"+obj+\"} ?s ?p ?o } UNION { VALUES ?s {\"+obj+\"} VALUES ?o {\"+subj+\"} ?s ?p ?o }\"\n",
    "        linkData[i][0] = linkData[i][0].translate(str.maketrans('', '', string.punctuation)).replace(\"httpsenwikipediaorgwiki\",\"\")\n",
    "        linkData[i][1] = linkData[i][1].translate(str.maketrans('', '', string.punctuation)).replace(\"httpsenwikipediaorgwiki\",\"\")\n",
    "        linkData[i][2] = linkData[i][2].translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        itemsInQuery[subj+obj] = linkData[i]\n",
    "        \n",
    "        if (i % batchSize == 0 and i != 0) or i == len(linkData) - 1:\n",
    "            keysToDelete = set()\n",
    "            queryTail += \"}\"\n",
    "            #print(queryTail)\n",
    "            queryTail = urllib.parse.quote(queryTail)\n",
    "            #print(queryHead + queryTail)\n",
    "            res = str(getWithRetry(queryHead + queryTail).content)\n",
    "            if 'Bad Request' in res:\n",
    "                raise Exception(\"Error in query\")\n",
    "            if \"http://www.wikidata.org/prop/direct/\" in res:\n",
    "                split_res = str(res[11:-1]).split(\"\\\\r\\\\n\")[:-1]\n",
    "                for row in split_res:\n",
    "                    csv_line = pp.commaSeparatedList.copy().addParseAction(pp.tokenMap(lambda s: s.strip('\"')))\n",
    "                    row = csv_line.parseString(row).asList()\n",
    "                    print(row)\n",
    "                    x = row[1].split(\"http://www.wikidata.org/prop/direct/\")\n",
    "                    wdp = x[1].split(\"\\\\\")[0]\n",
    "                    resSubj = \"<\" + row[0] + \">\"\n",
    "                    resObj = \"<\" + row[2] + \">\"\n",
    "                    if (resSubj+resObj in itemsInQuery):\n",
    "                        thisRow = itemsInQuery[resSubj+resObj]\n",
    "                        training_row = [thisRow[0], thisRow[1], thisRow[2], thisRow[3], wdp, \"Forwards\"]\n",
    "                        training_data.append(training_row)\n",
    "                        keysToDelete.add(resSubj+resObj)\n",
    "                    elif (resObj+resSubj in itemsInQuery):\n",
    "                        thisRow = itemsInQuery[resObj+resSubj]\n",
    "                        training_row = [thisRow[0], thisRow[1], thisRow[2], thisRow[3], wdp, \"Backwards\"]\n",
    "                        training_data.append(training_row)\n",
    "                        keysToDelete.add(resObj+resSubj)\n",
    "                    else:\n",
    "                        raise Exception(\"Did not find row from query result in map: \", resSubj, \" \", resObj)\n",
    "            \n",
    "            for key in keysToDelete:\n",
    "                del itemsInQuery[key]\n",
    "            for key in itemsInQuery:\n",
    "                test_data.append(itemsInQuery[key])\n",
    "                \n",
    "            itemsInQuery = {}\n",
    "            queryTail = \"select ?s ?p ?o where {\"\n",
    "            batchCount = batchCount + 1\n",
    "            print(\"batch \", batchCount, \" complete\")\n",
    "\n",
    "    return training_data, test_data\n",
    "\n",
    "# Neo4j Cypher lookup\n",
    "# DOES NOT Handle page redirects cleanly (as of now)\n",
    "def getStrongLinks(domain):\n",
    "    print(\"Finding strong links for: \", domain)\n",
    "    query = \"MATCH (source:Page {title: \\\"\"+domain+\"\\\"}) - [link1:Link] - (target:Page) - [link2:Link] - (source) WHERE link1 <> link2 RETURN distinct target.title\"\n",
    "    query_data = runWithRetry(query).data()\n",
    "    strong_links = [domain]\n",
    "    for res in query_data:\n",
    "        page = res[\"target.title\"]\n",
    "        strong_links.append(page)\n",
    "    print(\"Found \", str(len(strong_links)), \" strong links\")\n",
    "    return strong_links\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d2f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
